{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "508a9bbe",
   "metadata": {
    "tags": [
     "public"
    ]
   },
   "source": [
    "> **Public redacted copy** — outputs preserved, code shown with minimal changes.\n",
    "> A few lines that perform data access or model training have been commented with `[redacted]` notes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35255a4b",
   "metadata": {
    "tags": [
     "public",
     "autosave-helper"
    ]
   },
   "outputs": [],
   "source": [
    "# ---- Figure autosave helper (run once per session) ----\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "os.makedirs(\"figures\", exist_ok=True)\n",
    "_counter = {\"n\": 0}\n",
    "_old_show = plt.show\n",
    "\n",
    "def _save_then_show(*args, **kwargs):\n",
    "    _counter[\"n\"] += 1\n",
    "    fp = f\"figures/fig_{_counter['n']:02d}.png\"\n",
    "    plt.gcf().savefig(fp, dpi=300, bbox_inches=\"tight\")\n",
    "    _old_show(*args, **kwargs)\n",
    "\n",
    "plt.show = _save_then_show\n",
    "\n",
    "from matplotlib.figure import Figure\n",
    "_old_fig_show = Figure.show\n",
    "def _fig_save_then_show(self, *args, **kwargs):\n",
    "    _counter[\"n\"] += 1\n",
    "    fp = f\"figures/fig_{_counter['n']:02d}.png\"\n",
    "    self.savefig(fp, dpi=300, bbox_inches=\"tight\")\n",
    "    _old_fig_show(self, *args, **kwargs)\n",
    "Figure.show = _fig_save_then_show\n",
    "\n",
    "print(\"Autosave-on-show enabled → .[…redacted-path…]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38c5896-6c74-4c24-a5bd-3acdba3babfc",
   "metadata": {},
   "source": [
    "\n",
    "# Paper 3 — Supervised Logistic Model with Macro Variables\n",
    "\n",
    "This notebook extends the Paper 2 setup by adding macro-financial variables (inflation, real rate, QE proxy) to predict a **12‑month‑ahead recession indicator**.  \n",
    "It also produces **live forecasts** after the label cut-off (Mar 2024).\n",
    "\n",
    "**Inputs expected:**\n",
    "- Main macro dataset (CSV): `macro_core_monthly_1962-present_v03.csv` (or update the path below)\n",
    "  - Columns required: `Date, CPI_YoY, CPI_YoY_lag1, Real10y_spliced, FedBal_YoY, YC_10y_3m`\n",
    "- Recession indicator (monthly, 0/1) in one of two ways:\n",
    "  1) Included in the macro CSV as column **`recession`** (same as Paper 2), **or**\n",
    "  2) Provided in a separate CSV: `nber_recession_monthly.csv` with columns `Date, recession`\n",
    "\n",
    "**Conventions**\n",
    "- Date is monthly period end or first-of-month; parsed as datetime.\n",
    "- Label is created as `recession_t12 = recession.shift(-12)`.\n",
    "- Training window ends **2024-03**; forecasts start **2024-04**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd476ea6",
   "metadata": {
    "tags": [
     "public"
    ]
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73c73c8",
   "metadata": {
    "tags": [
     "public"
    ]
   },
   "outputs": [],
   "source": [
    "# --- Paths & existence checks ---\n",
    "DATA_DIR = Path(\"..[…redacted-path…]\")\n",
    "MACRO_CSV = DATA_DIR / \"macro_core_monthly_1962-present_v03.csv\"\n",
    "NBER_CSV  = DATA_DIR / \"usrec_monthly.csv\"\n",
    "\n",
    "missing = [p.name for p in [MACRO_CSV, NBER_CSV] if not p.exists()]\n",
    "if missing:\n",
    "    raise FileNotFoundError(\n",
    "        f\"Missing expected file(s) in ..[…redacted-path…] {', '.join(missing)}. \"\n",
    "        \"Check data folder mapping or filenames.\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92414a67",
   "metadata": {
    "tags": [
     "public"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro loaded: (766, 6) | 1962-01-01 → 2025-10-01\n"
     ]
    }
   ],
   "source": [
    "# --- Load macro CSV robustly (handles various date col names) ---\n",
    "#raw = pd.read_csv(MACRO_CSV)\n",
    "# [redacted] Critical operation disabled in public copy (data access or training).\n",
    "raw.columns = [c.strip() for c in raw.columns]\n",
    "\n",
    "date_col_candidates = [\"Date\", \"DATE\", \"date\", \"observation_date\", \"Month\", \"month\"]\n",
    "date_col = next((c for c in date_col_candidates if c in raw.columns), None)\n",
    "if date_col is None:\n",
    "    date_col = raw.columns[0]\n",
    "\n",
    "raw = raw.rename(columns={date_col: \"Date\"})\n",
    "raw[\"Date\"] = pd.to_datetime(raw[\"Date\"], errors=\"coerce\")\n",
    "\n",
    "macro = (raw.dropna(subset=[\"Date\"])\n",
    "             .sort_values(\"Date\")\n",
    "             .reset_index(drop=True))\n",
    "\n",
    "for c in macro.columns:\n",
    "    if c != \"Date\":\n",
    "        macro[c] = pd.to_numeric(macro[c], errors=\"coerce\")\n",
    "\n",
    "print(\"Macro loaded:\", macro.shape, \"|\", macro[\"Date\"].min().date(), \"→\", macro[\"Date\"].max().date())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca05bc7b",
   "metadata": {
    "tags": [
     "public"
    ]
   },
   "outputs": [],
   "source": [
    "# --- Load NBER monthly recession file and standardize to ['Date','recession'] ---\n",
    "#nber = pd.read_csv(NBER_CSV)\n",
    "# [redacted] Critical operation disabled in public copy (data access or training).\n",
    "\n",
    "if \"Date\" not in nber.columns:\n",
    "    if \"DATE\" in nber.columns:\n",
    "        nber = nber.rename(columns={\"DATE\": \"Date\"})\n",
    "    else:\n",
    "        nber = nber.rename(columns={nber.columns[0]: \"Date\"})\n",
    "nber[\"Date\"] = pd.to_datetime(nber[\"Date\"], errors=\"coerce\")\n",
    "\n",
    "label_col = next((c for c in [\"recession\", \"USREC\", \"USRECM\"] if c in nber.columns), None)\n",
    "if label_col is None:\n",
    "    raise KeyError(\"Could not find a recession indicator column in NBER CSV (expected one of recession/USREC/USRECM).\")\n",
    "\n",
    "nber[\"recession\"] = pd.to_numeric(nber[label_col], errors=\"coerce\").fillna(0).astype(int)\n",
    "nber = nber[[\"Date\", \"recession\"]].sort_values(\"Date\")\n",
    "\n",
    "df = (macro.merge(nber, on=\"Date\", how=\"left\")\n",
    "           .sort_values(\"Date\")\n",
    "           .reset_index(drop=True))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fffe668",
   "metadata": {
    "tags": [
     "public"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged df: (766, 7)\n",
      "Columns: ['Date', 'CPI_YoY', 'CPI_YoY_lag1', 'Real10y_spliced', 'FedBal_YoY', 'YC_10y_3m', 'recession']\n",
      "Date coverage: 1962-01-01 → 2025-10-01\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "<[…redacted-path…]\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th><[…redacted-path…]\n",
       "      <th>Date<[…redacted-path…]\n",
       "      <th>CPI_YoY<[…redacted-path…]\n",
       "      <th>CPI_YoY_lag1<[…redacted-path…]\n",
       "      <th>Real10y_spliced<[…redacted-path…]\n",
       "      <th>FedBal_YoY<[…redacted-path…]\n",
       "      <th>YC_10y_3m<[…redacted-path…]\n",
       "      <th>recession<[…redacted-path…]\n",
       "    <[…redacted-path…]\n",
       "  <[…redacted-path…]\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0<[…redacted-path…]\n",
       "      <td>1962-01-01<[…redacted-path…]\n",
       "      <td>0.67024<[…redacted-path…]\n",
       "      <td>NaN<[…redacted-path…]\n",
       "      <td>1.69976<[…redacted-path…]\n",
       "      <td>NaN<[…redacted-path…]\n",
       "      <td>1.36<[…redacted-path…]\n",
       "      <td>0.0<[…redacted-path…]\n",
       "    <[…redacted-path…]\n",
       "    <tr>\n",
       "      <th>1<[…redacted-path…]\n",
       "      <td>1962-02-01<[…redacted-path…]\n",
       "      <td>0.90483<[…redacted-path…]\n",
       "      <td>0.67024<[…redacted-path…]\n",
       "      <td>1.94517<[…redacted-path…]\n",
       "      <td>NaN<[…redacted-path…]\n",
       "      <td>1.31<[…redacted-path…]\n",
       "      <td>0.0<[…redacted-path…]\n",
       "    <[…redacted-path…]\n",
       "    <tr>\n",
       "      <th>2<[…redacted-path…]\n",
       "      <td>1962-03-01<[…redacted-path…]\n",
       "      <td>1.10590<[…redacted-path…]\n",
       "      <td>0.90483<[…redacted-path…]\n",
       "      <td>1.67410<[…redacted-path…]\n",
       "      <td>NaN<[…redacted-path…]\n",
       "      <td>1.21<[…redacted-path…]\n",
       "      <td>0.0<[…redacted-path…]\n",
       "    <[…redacted-path…]\n",
       "  <[…redacted-path…]\n",
       "<[…redacted-path…]\n",
       "<[…redacted-path…]"
      ],
      "text/plain": [
       "        Date  CPI_YoY  CPI_YoY_lag1  Real10y_spliced  FedBal_YoY  YC_10y_3m  \\\n",
       "0 1962-01-01  0.67024           NaN          1.69976         NaN       1.36   \n",
       "1 1962-02-01  0.90483       0.67024          1.94517         NaN       1.31   \n",
       "2 1962-03-01  1.10590       0.90483          1.67410         NaN       1.21   \n",
       "\n",
       "   recession  \n",
       "0        0.0  \n",
       "1        0.0  \n",
       "2        0.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Quick diagnostics (safe to delete ONCE CONFIRMED) ---\n",
    "print(\"Merged df:\", df.shape)\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "print(\"Date coverage:\", df[\"Date\"].min().date(), \"→\", df[\"Date\"].max().date())\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f35e73",
   "metadata": {
    "tags": [
     "public"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 1962-01-01 → 2024-03-01 | n = 747\n",
      "Test:  2017-01-01 → 2024-03-01 | n = 87\n",
      "Forecast window starts: 2024-04-01\n"
     ]
    }
   ],
   "source": [
    "# --- Feature engineering, windows, and splits (clean) ---\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, brier_score_loss, roc_curve\n",
    "\n",
    "# Ensure Date is the index (idempotent)\n",
    "if \"Date\" in df.columns:\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"Date\"]).sort_values(\"Date\").set_index(\"Date\")\n",
    "else:\n",
    "    # already indexed by Date\n",
    "    if df.index.name != \"Date\":\n",
    "        raise KeyError(f\"Expected index named 'Date', got {df.index.name!r}\")\n",
    "    df = df.sort_index()\n",
    "\n",
    "# 12-month-ahead target\n",
    "df[\"recession\"] = pd.to_numeric(df[\"recession\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "df[\"recession_t12\"] = df[\"recession\"].shift(-12)\n",
    "\n",
    "# Windows (spec)\n",
    "TRAIN_START = pd.Timestamp(\"1962-01-01\")\n",
    "TRAIN_END   = pd.Timestamp(\"2024-03-01\")\n",
    "HOLDOUT_START = pd.Timestamp(\"2017-01-01\")\n",
    "\n",
    "FEATURES = [\"CPI_YoY_lag1\",\"Real10y_spliced\",\"FedBal_YoY\",\"YC_10y_3m\"]\n",
    "\n",
    "# Early, friendly check (recommended)\n",
    "missing = [c for c in FEATURES if c not in df.columns]\n",
    "if missing:\n",
    "    raise KeyError(f\"Missing required FEATURES in df: {missing}\")\n",
    "\n",
    "# Masks\n",
    "train_mask     = (df.index >= TRAIN_START) & (df.index <= TRAIN_END)\n",
    "test_mask      = (df.index >= HOLDOUT_START) & (df.index <= TRAIN_END)\n",
    "forecast_mask  = (df.index >  TRAIN_END)\n",
    "\n",
    "# Splits\n",
    "train_df  = df.loc[train_mask].dropna(subset=[\"recession_t12\"]).copy()\n",
    "test_df   = df.loc[test_mask].copy()\n",
    "future_df = df.loc[forecast_mask].copy()\n",
    "\n",
    "print(\"Train:\", train_df.index.min().date(), \"→\", train_df.index.max().date(), \"| n =\", len(train_df))\n",
    "print(\"Test: \", test_df.index.min().date(),  \"→\", test_df.index.max().date(),  \"| n =\", len(test_df))\n",
    "print(\"Forecast window starts:\", future_df.index.min().date() if len(future_df) else \"—\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793ddcd7",
   "metadata": {
    "tags": [
     "public"
    ]
   },
   "outputs": [],
   "source": [
    "# --- Model 1: Simple logit (statsmodels) fit ---\n",
    "X_train = sm.add_constant(train_df[FEATURES], has_constant=\"add\").dropna()\n",
    "y_train = train_df.loc[X_train.index, \"recession_t12\"].astype(int)\n",
    "\n",
    "logit = sm.Logit(y_train, X_train)\n",
    "#res   = logit.fit(disp=False)\n",
    "# [redacted] Critical operation disabled in public copy (data access or training).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071d46ab",
   "metadata": {
    "tags": [
     "public"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 (Simple Logit) — AUC: 0.694 | Brier: 0.033\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk4AAAGGCAYAAACNCg6xAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAABa9ElEQVR4nO3dd3gU1f7H8femF0iQFggl9I5UqSK9i4oFvEgVUBSlXUEQfzQLV1QElWKhCBcQpalXECLSQaQKAlcQIjURQ0mAQOr5/bE3izEBdkOSSfm8nmcfd87M7H53ErMfZs6cYzPGGERERETkjtysLkBEREQkp1BwEhEREXGSgpOIiIiIkxScRERERJyk4CQiIiLiJAUnEREREScpOImIiIg4ScFJRERExEkKTiIiIiJOUnASyULz58/HZrM5Hh4eHhQvXpwnn3ySY8eOpblPfHw8s2bNonHjxgQGBuLr60vVqlUZPXo0Fy5cSHOfpKQkFi5cSJs2bShcuDCenp4ULVqUBx98kG+++YakpKTM/Ji3VKZMGR588ME01+3evRubzcb8+fNdft2NGzdis9nYuHHjHbft27cvZcqUcfk9XLF9+3YmTJjA5cuXXdrv6aefpkOHDo7lo0eP8tJLL1GvXj0KFChAwYIFadq0KcuWLUtz[…redacted-path…]",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Model 1: Evaluation on 2017+ holdout ---\n",
    "X_test = sm.add_constant(test_df[FEATURES], has_constant=\"add\").dropna()\n",
    "y_test = test_df.loc[X_test.index, \"recession_t12\"].astype(int)\n",
    "\n",
    "p_hat  = res.predict(X_test)\n",
    "\n",
    "auc   = roc_auc_score(y_test, p_hat)\n",
    "brier = brier_score_loss(y_test, p_hat)\n",
    "print(f\"Model 1 (Simple Logit) — AUC: {auc:.3f} | Brier: {brier:.3f}\")\n",
    "\n",
    "# ROC curve\n",
    "fpr, tpr, _ = roc_curve(y_test, p_hat)\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(fpr, tpr, label=f\"AUC={auc:.3f}\")\n",
    "plt.plot([0,1],[0,1],'--')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC — Holdout (2017+)\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# (Appendix material—move these out of the main flow if you keep them)\n",
    "# from sklearn.metrics import average_precision_score\n",
    "# auprc = average_precision_score(y_test, p_hat); print(f\"AUPRC: {auprc:.3f}\")\n",
    "# print(res.summary())\n",
    "# # Time-series prob plot also belongs in appendix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e070559d",
   "metadata": {
    "tags": [
     "public"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2 (L2 logit) — AUC: 0.676 | Brier: 0.055\n"
     ]
    }
   ],
   "source": [
    "# --- Model 2: Regularized logit (L2, sklearn) ---\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, brier_score_loss\n",
    "\n",
    "# Train data\n",
    "Xtr_lin = train_df[FEATURES]\n",
    "ytr     = train_df[\"recession_t12\"].astype(int)\n",
    "\n",
    "# Test data\n",
    "Xte_lin = test_df[FEATURES]\n",
    "yte     = test_df[\"recession_t12\"].astype(int)\n",
    "\n",
    "pipe_l2 = Pipeline(steps=[\n",
    "    (\"impute\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scale\",  StandardScaler()),\n",
    "    (\"clf\",    LogisticRegression(penalty=\"l2\", solver=\"lbfgs\", max_iter=1000))\n",
    "])\n",
    "\n",
    "#pipe_l2.fit(Xtr_lin, ytr)\n",
    "# [redacted] Critical operation disabled in public copy (data access or training).\n",
    "p_hat_reg = pipe_l2.predict_proba(Xte_lin)[:, 1]\n",
    "\n",
    "auc_reg   = roc_auc_score(yte, p_hat_reg)\n",
    "brier_reg = brier_score_loss(yte, p_hat_reg)\n",
    "print(f\"Model 2 (L2 logit) — AUC: {auc_reg:.3f} | Brier: {brier_reg:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed043a6c",
   "metadata": {
    "tags": [
     "public"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 3 (Nonlinear YC + L2) — AUC: 0.688 | Brier: 0.040\n"
     ]
    }
   ],
   "source": [
    "# --- Model 3: Nonlinear L2 (RBF features on YC_10y_3m) ---\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, brier_score_loss\n",
    "\n",
    "# Build RBFs from TRAIN quantiles of the yield-curve spread\n",
    "yc_train = train_df[\"YC_10y_3m\"].astype(float)\n",
    "q10, q50, q90 = np.quantile(yc_train.dropna(), [0.10, 0.50, 0.90])\n",
    "\n",
    "# bandwidth = average gap between adjacent knots (simple, stable)\n",
    "sigma = np.mean([abs(q50 - q10), abs(q90 - q50)]) or (yc_train.std() or 1.0)\n",
    "\n",
    "def rbf(x, c, s):\n",
    "    z = (x - c) / (s if s != 0 else 1.0)\n",
    "    return np.exp(-0.5 * z * z)\n",
    "\n",
    "# Create RBF features on train/test\n",
    "for frame in (train_df, test_df):\n",
    "    x = frame[\"YC_10y_3m\"].astype(float)\n",
    "    frame[\"YC_rbf1\"] = rbf(x, q10, sigma)\n",
    "    frame[\"YC_rbf2\"] = rbf(x, q50, sigma)\n",
    "    frame[\"YC_rbf3\"] = rbf(x, q90, sigma)\n",
    "\n",
    "FEATURES_NL = [\"CPI_YoY_lag1\",\"Real10y_spliced\",\"FedBal_YoY\",\"YC_rbf1\",\"YC_rbf2\",\"YC_rbf3\"]\n",
    "\n",
    "Xtr_nl = train_df[FEATURES_NL]\n",
    "Xte_nl = test_df[FEATURES_NL]\n",
    "ytr    = train_df[\"recession_t12\"].astype(int)\n",
    "yte    = test_df[\"recession_t12\"].astype(int)\n",
    "\n",
    "pipe_nl = Pipeline(steps=[\n",
    "    (\"impute\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scale\",  StandardScaler()),\n",
    "    (\"clf\",    LogisticRegression(penalty=\"l2\", solver=\"lbfgs\", max_iter=1000))\n",
    "])\n",
    "\n",
    "#pipe_nl.fit(Xtr_nl, ytr)\n",
    "# [redacted] Critical operation disabled in public copy (data access or training).\n",
    "p_hat_nl = pipe_nl.predict_proba(Xte_nl)[:, 1]\n",
    "\n",
    "auc_nl   = roc_auc_score(yte, p_hat_nl)\n",
    "brier_nl = brier_score_loss(yte, p_hat_nl)\n",
    "print(f\"Model 3 (Nonlinear YC + L2) — AUC: {auc_nl:.3f} | Brier: {brier_nl:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16209ce1",
   "metadata": {
    "tags": [
     "public"
    ]
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArIAAAHqCAYAAAD4TK2HAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAACIW0lEQVR4nOzdd1hT1/8H8HdIIGyQPUSGVnHWVWfVat111z1xVavWvReoVat1b60466p71Fqto47aurDOukBxgAjK3sn5/eGX/IwMCQKXwPv1PHk055577ztE4cPJuefKhBACRERERER6xkDqAEREREREOcFCloiIiIj0EgtZIiIiItJLLGSJiIiISC+xkCUiIiIivcRCloiIiIj0EgtZIiIiItJLLGSJiIiISC+xkCUiIiIivcRClohy3aZNmyCTyTQPhUIBZ2dndO3aFQ8ePMhwn5SUFKxevRq1a9eGlZUVTExMULZsWUycOBEREREZ7qNWq7F161Y0btwYdnZ2MDQ0hIODA1q1aoXDhw9DrVbn5cvMUHR0NGbPno0vvvgCTk5OMDc3R8WKFTFv3jwkJiam65+SkoIZM2bAw8MDSqUS3t7eWL58ebp+t2/fxpAhQ1C7dm2YmZlBJpPhzJkz6fqdOXNG62v[…redacted-path…]",
      "text/plain": [
       "<Figure size 700x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Side-by-side ROC comparison ---\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "fpr1, tpr1, _ = roc_curve(y_test, p_hat)       # Model 1 (statsmodels)\n",
    "fpr2, tpr2, _ = roc_curve(yte, p_hat_reg)      # Model 2 (L2)\n",
    "fpr3, tpr3, _ = roc_curve(yte, p_hat_nl)       # Model 3 (Nonlinear L2)\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.plot(fpr1, tpr1, lw=2, label=f\"Simple Logit (AUC={auc:.3f})\")\n",
    "plt.plot(fpr2, tpr2, lw=2, label=f\"L2 Logit (AUC={auc_reg:.3f})\")\n",
    "plt.plot(fpr3, tpr3, lw=2, label=f\"Nonlinear YC + L2 (AUC={auc_nl:.3f})\")\n",
    "plt.plot([0,1],[0,1],'--', lw=1)\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC — 2017+ holdout\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3950826",
   "metadata": {
    "tags": [
     "public"
    ]
   },
   "outputs": [],
   "source": [
    "# --- Final model selection already printed; keep variables: best_name, auc, brier, etc. ---\n",
    "\n",
    "def predict_probs_final(df_features):\n",
    "    \"\"\"\n",
    "    Input: DataFrame with at least the base FEATURES columns.\n",
    "           For nonlinear winner, YC RBFs are computed using TRAIN knots (q10,q50,q90,sigma).\n",
    "    Output: 1D numpy array of probabilities (12m-ahead recession).\n",
    "    \"\"\"\n",
    "    if best_name == \"simple_logit\":\n",
    "        X = sm.add_constant(df_features[FEATURES], has_constant=\"add\")\n",
    "        # align to training design (important if columns get re-ordered)\n",
    "        X = X.reindex(columns=logit.exog_names, fill_value=0).dropna()\n",
    "        return res.predict(X).values\n",
    "\n",
    "    elif best_name == \"l2_logit\":\n",
    "        return pipe_l2.predict_proba(df_features[FEATURES])[:, 1]\n",
    "\n",
    "    elif best_name == \"nonlinear_l2\":\n",
    "        df2 = df_features.copy()\n",
    "        x = df2[\"YC_10y_3m\"].astype(float)\n",
    "        s = (sigma if sigma != 0 else 1.0)\n",
    "        df2[\"YC_rbf1\"] = np.exp(-0.5 * ((x - q10)[…redacted-path…]\n",
    "        df2[\"YC_rbf2\"] = np.exp(-0.5 * ((x - q50)[…redacted-path…]\n",
    "        df2[\"YC_rbf3\"] = np.exp(-0.5 * ((x - q90)[…redacted-path…]\n",
    "        return pipe_nl.predict_proba(df2[FEATURES_NL])[:, 1]\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Unknown final model selection.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d37f8bc",
   "metadata": {
    "tags": [
     "public"
    ]
   },
   "outputs": [],
   "source": [
    "# --- Minimal shim for Cell [13] ---\n",
    "# Ensures best_name, logit, res exist after a restart, without touching other cells.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# 1) Winner flag (your flow uses the simple logit)\n",
    "if 'best_name' not in globals():\n",
    "    best_name = 'simple_logit'\n",
    "\n",
    "# 2) Recreate fitted model ONLY if missing (uses existing train_df + FEATURES from Cell [6])\n",
    "need_refit = ('logit' not in globals()) or ('res' not in globals())\n",
    "if need_refit:\n",
    "    # Sanity checks\n",
    "    if 'train_df' not in globals() or 'FEATURES' not in globals():\n",
    "        raise RuntimeError(\"Missing train_df and/or FEATURES. Re-run Cell [6] (feature engineering & splits) first.\")\n",
    "    missing = sorted(set(FEATURES + ['recession_t12']) - set(train_df.columns))\n",
    "    if missing:\n",
    "        raise RuntimeError(f\"Training data missing required columns: {missing}. Re-run upstream prep cells.\")\n",
    "\n",
    "    X_train = sm.add_constant(train_df[FEATURES], has_constant='add').replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    y_train = train_df.loc[X_train.index, 'recession_t12'].astype(int)\n",
    "    logit = sm.Logit(y_train, X_train)\n",
    "#    res   = logit.fit(disp=False)\n",
    "# [redacted] Critical operation disabled in public copy (data access or training).\n",
    "    print(\"Refit simple_logit (logit/res) for forecasting.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4a6588",
   "metadata": {
    "tags": [
     "public"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: paper3_live_forecasts.csv  | rows: 19\n"
     ]
    }
   ],
   "source": [
    "# --- Live forecasts for post-TRAIN_END observations (winner only) ---\n",
    "# Uses the features already observed in future_df (post 2024-03-01)\n",
    "if len(future_df):\n",
    "    p_live = predict_probs_final(future_df)\n",
    "    live_forecasts = future_df.copy()\n",
    "    live_forecasts[\"p_hat_final\"] = p_live\n",
    "    out_live = live_forecasts[[\"p_hat_final\"]].copy()\n",
    "    out_live.index.name = \"Date\"\n",
    "\n",
    "    # Save\n",
    "    out_live.to_csv(\"paper3_live_forecasts.csv\")\n",
    "    print(\"Saved: paper3_live_forecasts.csv  | rows:\", len(out_live))\n",
    "else:\n",
    "    print(\"No rows in future_df — nothing to forecast yet.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7716749b",
   "metadata": {
    "tags": [
     "public"
    ]
   },
   "outputs": [],
   "source": [
    "# --- Shim for scenarios: define future_index and H, and sanity-check inputs ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 1) future_index and H come from your already-built future_df (post-TRAIN_END)\n",
    "if 'future_df' not in globals():\n",
    "    raise RuntimeError(\"future_df is not defined. Re-run the split cell that creates future_df.\")\n",
    "future_index = future_df.index\n",
    "H = len(future_index)\n",
    "if H == 0:\n",
    "    raise RuntimeError(\"future_df has zero rows (no post-TRAIN_END dates). Nothing to scenario-forecast.\")\n",
    "\n",
    "# 2) Ensure FEATURES are available and covered by steps/bounds\n",
    "if 'FEATURES' not in globals():\n",
    "    raise RuntimeError(\"FEATURES not defined. Re-run the cell that sets FEATURES.\")\n",
    "missing_steps  = sorted(set(FEATURES) - set(steps.keys()))\n",
    "missing_bounds = sorted(set(FEATURES) - set(bounds.keys()))\n",
    "if missing_steps or missing_bounds:\n",
    "    raise RuntimeError(\n",
    "        f\"steps/bounds missing keys.\\n\"\n",
    "        f\"  Missing in steps:  {missing_steps}\\n\"\n",
    "        f\"  Missing in bounds: {missing_bounds}\\n\"\n",
    "        f\"Add entries for all FEATURES or drop those features from the scenario.\"\n",
    "    )\n",
    "\n",
    "# 3) Optional: verify last row has no NaNs for these FEATURES\n",
    "if 'df' not in globals():\n",
    "    raise RuntimeError(\"df not defined. Re-run earlier loading/feature cells.\")\n",
    "_ = df.iloc[-1][FEATURES].astype(float)\n",
    "if _.isna().any():\n",
    "    bad = list(_.index[_.isna()])\n",
    "    raise RuntimeError(f\"Latest row has NaNs for: {bad}. Fix upstream feature engineering before scenarios.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae12108",
   "metadata": {
    "tags": [
     "public"
    ]
   },
   "outputs": [],
   "source": [
    "# --- Multi-feature scenario setup (replace the simpler YC-only bit) ---\n",
    "\n",
    "# last observed levels for all FEATURES\n",
    "last = df.iloc[-1]\n",
    "last_vals = last[FEATURES].astype(float)\n",
    "\n",
    "def path_linear(start, step, n, lo=None, hi=None):\n",
    "    arr = start + step * np.arange(1, n+1, dtype=float)\n",
    "    if lo is not None: arr = np.maximum(arr, lo)\n",
    "    if hi is not None: arr = np.minimum(arr, hi)\n",
    "    return arr\n",
    "\n",
    "# monthly step sizes (percentage-point moves per month)\n",
    "steps = {\n",
    "    \"CPI_YoY_lag1\":    {\"baseline\": -0.05, \"easing\": -0.15, \"stress\": +0.10},\n",
    "    \"Real10y_spliced\": {\"baseline\":  0.00, \"easing\": -0.10, \"stress\": +0.08},\n",
    "    \"YC_10y_3m\":       {\"baseline\": +0.02, \"easing\": +0.08, \"stress\": -0.06},\n",
    "    \"FedBal_YoY\":      {\"baseline\":  0.00, \"easing\": +1.50, \"stress\": -1.50},\n",
    "}\n",
    "bounds = {\n",
    "    \"CPI_YoY_lag1\":    (-1.0, 8.0),\n",
    "    \"Real10y_spliced\": (-2.0, 5.0),\n",
    "    \"YC_10y_3m\":       (-3.0, 3.0),\n",
    "    \"FedBal_YoY\":      (-50.0, 100.0),\n",
    "}\n",
    "\n",
    "def make_scenarios(last_vals, n, features):\n",
    "    scens = {}\n",
    "    for name in [\"baseline\", \"easing\", \"stress\"]:\n",
    "        df_s = pd.DataFrame(index=future_index, columns=features, dtype=float)\n",
    "        for feat in features:\n",
    "            df_s[feat] = path_linear(\n",
    "                start=last_vals[feat],\n",
    "                step=steps[feat][name],\n",
    "                n=n,\n",
    "                lo=bounds[feat][0], hi=bounds[feat][1]\n",
    "            )\n",
    "        scens[name] = df_s\n",
    "    return scens\n",
    "\n",
    "scenarios = make_scenarios(last_vals, H, FEATURES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8dbe0e",
   "metadata": {
    "tags": [
     "public"
    ]
   },
   "outputs": [],
   "source": [
    "# --- Shim for MC bands: ensure prerequisites exist ---\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "# future horizon / index\n",
    "if 'future_df' not in globals():\n",
    "    raise RuntimeError(\"future_df is not defined. Re-run the split cell that creates train_df/test_df/future_df.\")\n",
    "future_index = future_df.index\n",
    "H = len(future_index)\n",
    "if H == 0:\n",
    "    raise RuntimeError(\"future_df has zero rows (no post-TRAIN_END dates). Nothing to simulate.\")\n",
    "\n",
    "# features and last values\n",
    "if 'FEATURES' not in globals():\n",
    "    raise RuntimeError(\"FEATURES not defined. Re-run the cell that sets FEATURES.\")\n",
    "if 'df' not in globals():\n",
    "    raise RuntimeError(\"df not defined. Re-run earlier loading/feature cells.\")\n",
    "last_vals = df.iloc[-1][FEATURES].astype(float)\n",
    "\n",
    "# ensure make_scenarios & inputs exist\n",
    "if 'make_scenarios' not in globals():\n",
    "    raise RuntimeError(\"make_scenarios(...) is not defined. Re-run the scenario-setup cell that defines it.\")\n",
    "if 'steps' not in globals() or 'bounds' not in globals():\n",
    "    raise RuntimeError(\"steps/bounds not defined. Re-run the scenario-setup cell.\")\n",
    "missing_steps  = sorted(set(FEATURES) - set(steps.keys()))\n",
    "missing_bounds = sorted(set(FEATURES) - set(bounds.keys()))\n",
    "if missing_steps or missing_bounds:\n",
    "    raise RuntimeError(\n",
    "        f\"steps/bounds missing keys for FEATURES.\\n\"\n",
    "        f\"  Missing in steps:  {missing_steps}\\n\"\n",
    "        f\"  Missing in bounds: {missing_bounds}\\n\"\n",
    "        f\"Add entries or restrict FEATURES for scenarios.\"\n",
    "    )\n",
    "\n",
    "# (re)build scenarios if absent\n",
    "if 'scenarios' not in globals():\n",
    "    scenarios = make_scenarios(last_vals, H, FEATURES)\n",
    "\n",
    "# predictor must exist\n",
    "if 'predict_probs_final' not in globals():\n",
    "    raise RuntimeError(\"predict_probs_final(...) not found. Re-run Cell [12] where it is defined.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617616dc",
   "metadata": {
    "tags": [
     "public"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: paper3_scenario_probs_mc_baseline.csv | rows: 19\n",
      "Saved: paper3_scenario_probs_mc_easing.csv | rows: 19\n",
      "Saved: paper3_scenario_probs_mc_stress.csv | rows: 19\n"
     ]
    }
   ],
   "source": [
    "# --- Monte Carlo input-uncertainty bands (vary YC_10y_3m only) ---\n",
    "rng = np.random.default_rng(42)\n",
    "yc_std = float(train_df[\"YC_10y_3m\"].std())  # scale of typical monthly spread moves\n",
    "N = 500  # number of MC paths\n",
    "\n",
    "bands = {}\n",
    "for name, df_s in scenarios.items():\n",
    "    # replicate scenario YC path with Gaussian noise each month\n",
    "    paths = []\n",
    "    for _ in range(N):\n",
    "        noisy = df_s.copy()\n",
    "        noisy[\"YC_10y_3m\"] = noisy[\"YC_10y_3m\"].values + rng.normal(0.0, 0.5*yc_std, size=len(df_s))\n",
    "        paths.append(predict_probs_final(noisy))\n",
    "    arr = np.vstack(paths)  # N x H\n",
    "    bands[name] = {\n",
    "        \"p50\": np.median(arr, axis=0),\n",
    "        \"p10\": np.percentile(arr, 10, axis=0),\n",
    "        \"p90\": np.percentile(arr, 90, axis=0),\n",
    "    }\n",
    "\n",
    "# Collect to long and wide frames\n",
    "band_frames = []\n",
    "for name, d in bands.items():\n",
    "    tmp = pd.DataFrame({\"Date\": future_index,\n",
    "                        \"p10\": d[\"p10\"], \"p50\": d[\"p50\"], \"p90\": d[\"p90\"]})\n",
    "    tmp[\"scenario\"] = name\n",
    "    band_frames.append(tmp.set_index(\"Date\"))\n",
    "bands_long = pd.concat(band_frames).reset_index()\n",
    "bands_wide = {}\n",
    "for name in scenarios.keys():\n",
    "    sub = bands_long[bands_long[\"scenario\"] == name].set_index(\"Date\")[[\"p10\",\"p50\",\"p90\"]]\n",
    "    bands_wide[name] = sub\n",
    "\n",
    "# Save MC bands per scenario\n",
    "for name, dfw in bands_wide.items():\n",
    "    fn = f\"paper3_scenario_probs_mc_{name}.csv\"\n",
    "    dfw.to_csv(fn)\n",
    "    print(\"Saved:\", fn, \"| rows:\", len(dfw))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fe789e",
   "metadata": {
    "tags": [
     "public"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: paper3_scenario_probs.csv | cols: ['baseline', 'easing', 'stress']\n"
     ]
    }
   ],
   "source": [
    "# --- Scenario probabilities (winner only) + save a single canonical CSV ---\n",
    "scenario_probs = {\n",
    "    name: pd.Series(predict_probs_final(df_s), index=future_index, name=name)\n",
    "    for name, df_s in scenarios.items()\n",
    "}\n",
    "\n",
    "scen_wide = pd.concat(scenario_probs.values(), axis=1)\n",
    "scen_wide.index.name = \"Date\"\n",
    "scen_wide.to_csv(\"paper3_scenario_probs.csv\")\n",
    "print(\"Saved: paper3_scenario_probs.csv | cols:\", list(scen_wide.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7526eb22",
   "metadata": {
    "tags": [
     "public"
    ]
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk4AAAGGCAYAAACNCg6xAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAABQZklEQVR4nO3dd1QU198G8GeBXZaOoIAFFTViR4NRARUr9hqjiUasiaYZWxKNif0NGo0xDWJs2EVjiS1RYuyiQcWKsaJoBDtFROp9/+C3E1cWmEVglH0+5+wB7t7Z/c5lgYd7Z2ZVQggBIiIiIiqQmdIFEBEREb0sGJyIiIiIZGJwIiIiIpKJwYmIiIhIJgYnIiIiIpkYnIiIiIhkYnAiIiIikonBiYiIiEgmBiciIiIimRicXiKhoaFQqVTSzcLCApUqVcKQIUPw77[…redacted-path…]",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Appendix: PR vs threshold (final model)\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "p_final_test = predict_probs_final(test_df)\n",
    "prec, rec, thr = precision_recall_curve(y_test, p_final_test)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(thr, prec[:-1], label=\"Precision\")\n",
    "plt.plot(thr, rec[:-1],  label=\"Recall\")\n",
    "# Optional: if you computed best_thr for the final model\n",
    "# plt.axvline(x=best_thr, ls='--', label=f\"Youden={best_thr:.3f}\")\n",
    "plt.xlabel(\"Threshold\"); plt.ylabel(\"Score\")\n",
    "plt.title(\"Precision–Recall Tradeoff vs Threshold (Final Model)\")\n",
    "plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1494e0",
   "metadata": {
    "tags": [
     "public"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: paper3_live_forecasts.csv  | rows: 19\n"
     ]
    }
   ],
   "source": [
    "# --- Live forecasts (winner only) + save (replaces your cell [16]) ---\n",
    "if len(future_df):\n",
    "    p_live = predict_probs_final(future_df)\n",
    "    live_forecasts = future_df.copy()\n",
    "    live_forecasts[\"p_hat_final\"] = p_live\n",
    "\n",
    "    out_live = live_forecasts[[\"p_hat_final\"]].copy()\n",
    "    out_live.index.name = \"Date\"\n",
    "    out_live.to_csv(\"paper3_live_forecasts.csv\")\n",
    "    print(\"Saved: paper3_live_forecasts.csv  | rows:\", len(out_live))\n",
    "else:\n",
    "    print(\"No rows in future_df — nothing to forecast yet.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5710c16",
   "metadata": {
    "tags": [
     "public"
    ]
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA90AAAGGCAYAAABmGOKbAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAACd7UlEQVR4nOzdd1yV5f/H8ddhCwKKCg5QcSDuvcWtpS0z03LPbJipLdtlw7TxteHIkebIrNSy1MqZ4N57i+DAgcgQZZ1z[…redacted-path…]",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Appendix: quick live series plot (optional)\n",
    "#out_live = pd.read_csv(\"paper3_live_forecasts.csv\", parse_dates=[\"Date\"]).set_index(\"Date\")\n",
    "# [redacted] Critical operation disabled in public copy (data access or training).\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(out_live.index, out_live[\"p_hat_final\"])\n",
    "plt.xlabel(\"Date\"); plt.ylabel(\"Recession Prob (12m ahead)\")\n",
    "plt.title(\"Live Forecast — Apr 2024 onward (Final Model)\")\n",
    "plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7383f2f0",
   "metadata": {
    "tags": [
     "public"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# ---------- 1) Historical monthly volatilities (on changes) ----------\n",
    "# Use last 10 years for a realistic modern-vol estimate (tweak if you want)\n",
    "hist_cut = df.index.max() - pd.DateOffset(years=10)\n",
    "hist = df.loc[df.index >= hist_cut, FEATURES].astype(float).ffill()\n",
    "\n",
    "# monthly change std per feature (percentage-point changes)\n",
    "d_hist = hist.diff()\n",
    "sigma = d_hist.std().to_dict()   # e.g., {\"CPI_YoY_lag1\": 0.25, ...}\n",
    "\n",
    "# Reasonable hard bounds to avoid absurd values in sims\n",
    "bounds = {\n",
    "    \"CPI_YoY_lag1\": (-1.0, 8.0),\n",
    "    \"Real10y_spliced\": (-2.0, 5.0),\n",
    "    \"YC_10y_3m\": (-3.0, 3.0),\n",
    "    \"FedBal_YoY\": (-50.0, 100.0),\n",
    "}\n",
    "\n",
    "# ---------- 2) Monte Carlo simulator around a deterministic scenario path ----------\n",
    "def simulate_probs_around_path(path_df, sims=500, seed=42):\n",
    "    \"\"\"Return quantiles (p10, p50, p90) of recession_prob_t12 for each month.\"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    T = len(path_df)\n",
    "    feats = path_df.columns.tolist()\n",
    "    idx = path_df.index\n",
    "\n",
    "    # Pre-allocate matrix for probabilities: (sims, T)\n",
    "    P = np.empty((sims, T), dtype=float)\n",
    "\n",
    "    for s in range(sims):\n",
    "        # Start at deterministic path; add Gaussian monthly shocks to changes\n",
    "        sim = path_df.copy()\n",
    "        for f in feats:\n",
    "            # random monthly shocks to the LEVEL via shocks on changes (random walk with drift)\n",
    "            shocks = rng.normal(loc=0.0, scale=sigma.get(f, 0.0), size=T)\n",
    "            sim[f] = sim[f].iloc[0] + np.cumsum(np.r_[0.0, np.diff(path_df[f].values) + shocks[1:]])\n",
    "            # clamp\n",
    "            sim[f] = sim[f].clip(lower=bounds[f][0], upper=bounds[f][1])\n",
    "\n",
    "        # Predict with fixed trained model\n",
    "        p = pd.Series(predict_probs_final(sim), index=idx).astype(float)\n",
    "        P[s, :] = p.values\n",
    "\n",
    "    # Quantiles across simulations for each date\n",
    "    q10 = np.quantile(P, 0.10, axis=0)\n",
    "    q50 = np.quantile(P, 0.50, axis=0)\n",
    "    q90 = np.quantile(P, 0.90, axis=0)\n",
    "\n",
    "    out = pd.DataFrame({\"Date\": idx, \"p10\": q10, \"p50\": q50, \"p90\": q90}).set_index(\"Date\")\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02dff6be",
   "metadata": {
    "scrolled": true,
    "tags": [
     "public"
    ]
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABEEAAAHqCAYAAADrglBeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOzdZ3wUVRcH4P/W9N5DAiQk9N5DD6F3EEVQaYKAIr2DdKUj0i0IgojKq6AUkR5KKKEEQpWWhJLe27aZ+37Y3cluNhVCQsJ5fq7sTr0zmW1nzz1XxBhjIIQQQgghhBBCCKngxGXdAEIIIYQQQgghhJDSQEEQQgghhBBCCCGEvBUoCEIIIYQQQgghhJC3AgVBCCGEEEIIIYQQ8lagIAghhBBCCCGEEELeChQEIYQQQgghhBBCyFuBgiCEEEIIIYQQQgh5K1AQhBBCCCGEEEIIIW8FCoIQQgghhBBCCCHkrUBBEEIquEuXLqF[…redacted-path…]",
      "text/plain": [
       "<Figure size 1100x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved MC scenario bands → paper3_scenario_probs_mc.csv | rows: 57\n"
     ]
    }
   ],
   "source": [
    "# Ensure you already created `scenarios` (baseline/easing/stress) as before\n",
    "# stable seeds per scenario\n",
    "seed_map = {\"baseline\": 123, \"easing\": 124, \"stress\": 125}\n",
    "\n",
    "mc = {}\n",
    "for name, path_df in scenarios.items():\n",
    "    mc[name] = simulate_probs_around_path(\n",
    "        path_df[FEATURES], sims=500, seed=seed_map[name]\n",
    "    )\n",
    "\n",
    "# Plot ribbons + medians\n",
    "plt.figure(figsize=(11,5))\n",
    "colors = {\"baseline\":\"tab:blue\",\"easing\":\"tab:green\",\"stress\":\"tab:red\"}\n",
    "\n",
    "for name in [\"baseline\",\"easing\",\"stress\"]:\n",
    "    q = mc[name]\n",
    "    plt.fill_between(q.index, q[\"p10\"], q[\"p90\"], alpha=0.2, label=f\"{name.capitalize()} (10–90%)\",\n",
    "                     color=colors[name])\n",
    "    plt.plot(q.index, q[\"p50\"], lw=2, color=colors[name], label=f\"{name.capitalize()} median\")\n",
    "\n",
    "plt.ylim(0, 1)\n",
    "plt.ylabel(\"Recession Prob (12m ahead)\")\n",
    "plt.title(\"Scenario-based Conditional Recession Probabilities — with Uncertainty Bands\")\n",
    "plt.legend(ncol=3, loc=\"upper center\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Tidy save for appendix (long format)\n",
    "out_list = []\n",
    "for name, q in mc.items():\n",
    "    tmp = q.reset_index().assign(scenario=name)\n",
    "    out_list.append(tmp)\n",
    "out = pd.concat(out_list, ignore_index=True)\n",
    "out = out[[\"Date\",\"scenario\",\"p10\",\"p50\",\"p90\"]]\n",
    "\n",
    "out_path = Path(\"paper3_scenario_probs_mc.csv\")  # root, canonical\n",
    "out.to_csv(out_path, index=False)\n",
    "print(\"Saved MC scenario bands →\", out_path, \"| rows:\", len(out))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e1dac0",
   "metadata": {
    "tags": [
     "public"
    ]
   },
   "outputs": [],
   "source": [
    "# --- Scenario setup (robust to Date as column or unnamed index) ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# 0) FEATURES (only if not already set)\n",
    "try:\n",
    "    FEATURES\n",
    "except NameError:\n",
    "    FEATURES = [\"CPI_YoY_lag1\", \"Real10y_spliced\", \"FedBal_YoY\", \"YC_10y_3m\"]\n",
    "\n",
    "# 1) Ensure df exists and has a proper datetime index named \"Date\"\n",
    "if \"Date\" in getattr(df, \"columns\", []):\n",
    "    df = df.copy()\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"Date\"]).sort_values(\"Date\").set_index(\"Date\")\n",
    "else:\n",
    "    # Already indexed by dates (possibly unnamed)\n",
    "    df = df.copy()\n",
    "    df.index = pd.to_datetime(df.index, errors=\"coerce\")\n",
    "    # Can't use dropna(subset=[df.index.name]) if name is None; use index mask instead\n",
    "    df = df.loc[~pd.isna(df.index)].sort_index()\n",
    "    if df.index.name != \"Date\":\n",
    "        df.index.name = \"Date\"\n",
    "\n",
    "# 2) Check that all FEATURES exist\n",
    "missing_feats = sorted(set(FEATURES) - set(df.columns))\n",
    "if missing_feats:\n",
    "    raise KeyError(f\"DataFrame is missing required FEATURES columns: {missing_feats}\")\n",
    "\n",
    "# 3) Last non-NA values for FEATURES and last observed date\n",
    "last_row  = df[FEATURES].ffill().iloc[-1]\n",
    "last_date = df.index.max()\n",
    "\n",
    "# 4) Forecast horizon and future index\n",
    "horizon_months = 24  # adjust to 36/48 if desired\n",
    "future_index = pd.date_range(last_date + pd.offsets.MonthBegin(1),\n",
    "                             periods=horizon_months, freq=\"MS\")\n",
    "H = len(future_index)\n",
    "\n",
    "# 5) Values for the scenario generator\n",
    "last_vals = last_row.astype(float)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851ce810",
   "metadata": {
    "tags": [
     "public"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2 (L2 logit) — AUC: 0.676 | Brier: 0.055\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, brier_score_loss\n",
    "\n",
    "# Use FEATURES from Cell E\n",
    "Xtr = train_df[FEATURES].astype(float)\n",
    "ytr = train_df[\"recession_t12\"].astype(int)\n",
    "Xte = test_df[FEATURES].astype(float)\n",
    "yte = test_df[\"recession_t12\"].astype(int)\n",
    "\n",
    "pipe_l2 = Pipeline(steps=[\n",
    "    (\"impute\", SimpleImputer(strategy=\"median\")),   # fit on TRAIN only\n",
    "    (\"scale\",  StandardScaler()),\n",
    "    (\"clf\",    LogisticRegression(penalty=\"l2\", C=1.0, solver=\"lbfgs\", max_iter=1000))\n",
    "])\n",
    "#pipe_l2.fit(Xtr, ytr)\n",
    "# [redacted] Critical operation disabled in public copy (data access or training).\n",
    "\n",
    "p_hat_reg = pipe_l2.predict_proba(Xte)[:, 1]\n",
    "auc_reg   = roc_auc_score(yte, p_hat_reg)\n",
    "brier_reg = brier_score_loss(yte, p_hat_reg)\n",
    "print(f\"Model 2 (L2 logit) — AUC: {auc_reg:.3f} | Brier: {brier_reg:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943b2230",
   "metadata": {
    "tags": [
     "public"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 3 (Nonlinear YC + L2) — AUC: 0.688 | Brier: 0.040\n"
     ]
    }
   ],
   "source": [
    "# --- Model 3: Nonlinear L2 (RBF features on YC_10y_3m) ---\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, brier_score_loss\n",
    "\n",
    "# RBF knots from TRAIN quantiles of YC_10y_3m\n",
    "yc_train = train_df[\"YC_10y_3m\"].astype(float).dropna()\n",
    "q10, q50, q90 = np.quantile(yc_train, [0.10, 0.50, 0.90])\n",
    "sigma = np.mean([abs(q50 - q10), abs(q90 - q50)]) or (yc_train.std() or 1.0)\n",
    "\n",
    "def rbf(series, c, s):\n",
    "    z = (series - c) / (s if s != 0 else 1.0)\n",
    "    return np.exp(-0.5 * z * z)\n",
    "\n",
    "# Build temp frames with RBFs (don’t mutate originals)\n",
    "train_nl = train_df.copy()\n",
    "test_nl  = test_df.copy()\n",
    "for frame in (train_nl, test_nl):\n",
    "    x = frame[\"YC_10y_3m\"].astype(float)\n",
    "    frame[\"YC_rbf1\"] = rbf(x, q10, sigma)\n",
    "    frame[\"YC_rbf2\"] = rbf(x, q50, sigma)\n",
    "    frame[\"YC_rbf3\"] = rbf(x, q90, sigma)\n",
    "\n",
    "FEATURES_NL = [\"CPI_YoY_lag1\",\"Real10y_spliced\",\"FedBal_YoY\",\"YC_rbf1\",\"YC_rbf2\",\"YC_rbf3\"]\n",
    "\n",
    "Xtr_nl = train_nl[FEATURES_NL]\n",
    "Xte_nl = test_nl[FEATURES_NL]\n",
    "ytr_nl = train_nl[\"recession_t12\"].astype(int)\n",
    "yte_nl = test_nl[\"recession_t12\"].astype(int)\n",
    "\n",
    "pipe_nl = Pipeline(steps=[\n",
    "    (\"impute\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scale\",  StandardScaler()),\n",
    "    (\"clf\",    LogisticRegression(penalty=\"l2\", solver=\"lbfgs\", max_iter=1000))\n",
    "])\n",
    "\n",
    "#pipe_nl.fit(Xtr_nl, ytr_nl)\n",
    "# [redacted] Critical operation disabled in public copy (data access or training).\n",
    "p_hat_nl = pipe_nl.predict_proba(Xte_nl)[:, 1]\n",
    "\n",
    "auc_nl   = roc_auc_score(yte_nl, p_hat_nl)\n",
    "brier_nl = brier_score_loss(yte_nl, p_hat_nl)\n",
    "print(f\"Model 3 (Nonlinear YC + L2) — AUC: {auc_nl:.3f} | Brier: {brier_nl:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ba4db1",
   "metadata": {
    "tags": [
     "public"
    ]
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArIAAAHqCAYAAAD4TK2HAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAACIW0lEQVR4nOzdd1hT1/8H8HdIIGyQPUSGVnHWVWfVat111z1xVavWvReoVat1b60466p71Fqto47aurDOukBxgAjK3sn5/eGX/IwMCQKXwPv1PHk055577ztE4cPJuefKhBACRERERER6xkDqAEREREREOcFCloiIiIj0EgtZIiIiItJLLGSJiIiISC+xkCUiIiIivcRCloiIiIj0EgtZIiIiItJLLGSJiIiISC+xkCUiIiIivcRClohy3aZNmyCTyTQPhUIBZ2dndO3aFQ8ePMhwn5SUFKxevRq1a9eGlZUVTExMULZsWUycOBEREREZ7qNWq7F161Y0btwYdnZ2MDQ0hIODA1q1aoXDhw9DrVbn5cvMUHR0NGbPno0vvvgCTk5OMDc3R8WKFTFv3jwkJiam65+SkoIZM2bAw8MDSqUS3t7eWL58ebp+t2/fxpAhQ1C7dm2YmZlBJpPhzJkz6fqdOXNG62v[…redacted-path…]",
      "text/plain": [
       "<Figure size 700x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- ROC comparison on 2017+ holdout ---\n",
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Model 1 used statsmodels and dropped NA rows; use the same y_test it produced\n",
    "# (y_test and p_hat were created in your Model 1 cell)\n",
    "fpr1, tpr1, _ = roc_curve(y_test, p_hat)\n",
    "\n",
    "# Models 2 & 3 used imputer, so they score the full test_df rows\n",
    "fpr2, tpr2, _ = roc_curve(yte,    p_hat_reg)\n",
    "fpr3, tpr3, _ = roc_curve(yte_nl, p_hat_nl)\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.plot(fpr1, tpr1, lw=2, label=f\"Simple Logit (AUC={auc:.3f})\")\n",
    "plt.plot(fpr2, tpr2, lw=2, label=f\"L2 Logit (AUC={auc_reg:.3f})\")\n",
    "plt.plot(fpr3, tpr3, lw=2, label=f\"Nonlinear YC + L2 (AUC={auc_nl:.3f})\")\n",
    "plt.plot([0,1],[0,1],'--', lw=1)\n",
    "plt.xlabel(\"False Positive Rate\"); plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC — 2017+ holdout\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d574ad",
   "metadata": {
    "tags": [
     "public"
    ]
   },
   "outputs": [],
   "source": [
    "#Ablation: Yield-Curve-Only Model\n",
    "\n",
    "Xtr_min = train_df[[\"YC_10y_3m\"]].astype(float)\n",
    "Xte_min = test_df[[\"YC_10y_3m\"]].astype(float)\n",
    "\n",
    "sc_min  = StandardScaler()\n",
    "#Xtrz_m  = sc_min.fit_transform(Xtr_min)\n",
    "# [redacted] Critical operation disabled in public copy (data access or training).\n",
    "Xtez_m  = sc_min.transform(Xte_min)\n",
    "\n",
    "clf_min = LogisticRegression(penalty=\"l2\", C=1.0, solver=\"lbfgs\", max_iter=1000)\n",
    "#clf_min.fit(Xtrz_m, ytr)\n",
    "# [redacted] Critical operation disabled in public copy (data access or training).\n",
    "p_hat_min = clf_min.predict_proba(Xtez_m)[:,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fce503",
   "metadata": {
    "tags": [
     "public"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 3 (Nonlinear YC + L2) — AUC: 0.688 | Brier: 0.040\n"
     ]
    }
   ],
   "source": [
    "# --- Model 3: Nonlinear L2 (RBF on YC_10y_3m) ---\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, brier_score_loss\n",
    "\n",
    "# TRAIN-only knots and bandwidth\n",
    "yc_train = train_df[\"YC_10y_3m\"].astype(float).dropna().values\n",
    "q10, q50, q90 = np.quantile(yc_train, [0.10, 0.50, 0.90])\n",
    "sigma = np.mean([abs(q50 - q10), abs(q90 - q50)]) or (np.std(yc_train) or 1.0)\n",
    "\n",
    "def rbf(x, c, s):\n",
    "    z = (x - c) / (s if s != 0 else 1.0)\n",
    "    return np.exp(-0.5 * z * z)\n",
    "\n",
    "def featurize(df0):\n",
    "    x = df0[[\"CPI_YoY_lag1\",\"Real10y_spliced\",\"FedBal_YoY\",\"YC_10y_3m\"]].astype(float).copy()\n",
    "    x[\"YC_rbf1\"] = rbf(x[\"YC_10y_3m\"].values, q10, sigma)\n",
    "    x[\"YC_rbf2\"] = rbf(x[\"YC_10y_3m\"].values, q50, sigma)\n",
    "    x[\"YC_rbf3\"] = rbf(x[\"YC_10y_3m\"].values, q90, sigma)\n",
    "    return x\n",
    "\n",
    "Xtr_nl = featurize(train_df)\n",
    "Xte_nl = featurize(test_df)\n",
    "ytr_nl = train_df[\"recession_t12\"].astype(int)\n",
    "yte_nl = test_df[\"recession_t12\"].astype(int)\n",
    "\n",
    "pipe_nl = Pipeline(steps=[\n",
    "    (\"impute\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scale\",  StandardScaler()),\n",
    "    (\"clf\",    LogisticRegression(penalty=\"l2\", solver=\"lbfgs\", max_iter=1000))\n",
    "])\n",
    "\n",
    "#pipe_nl.fit(Xtr_nl, ytr_nl)\n",
    "# [redacted] Critical operation disabled in public copy (data access or training).\n",
    "p_hat_nl = pipe_nl.predict_proba(Xte_nl)[:, 1]\n",
    "\n",
    "auc_nl   = roc_auc_score(yte_nl, p_hat_nl)\n",
    "brier_nl = brier_score_loss(yte_nl, p_hat_nl)\n",
    "print(f\"Model 3 (Nonlinear YC + L2) — AUC: {auc_nl:.3f} | Brier: {brier_nl:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24cde6a",
   "metadata": {
    "tags": [
     "public"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Youden thr (NL)=0.117 | TP=2 FP=27 FN=0 TN=58\n",
      "Precision: 0.06896551724137931 Recall: 1.0 F1: 0.12903225806451613\n"
     ]
    }
   ],
   "source": [
    "#appendix \n",
    "\n",
    "from sklearn.metrics import roc_curve, confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n",
    "fpr, tpr, thr = roc_curve(yte_nl, p_hat_nl)\n",
    "best_thr_nl = thr[(tpr - fpr).argmax()]\n",
    "y_pred_nl   = (p_hat_nl >= best_thr_nl).astype(int)\n",
    "\n",
    "cm = confusion_matrix(yte_nl, y_pred_nl, labels=[0,1])\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "print(f\"Youden thr (NL)={best_thr_nl:.3f} | TP={tp} FP={fp} FN={fn} TN={tn}\")\n",
    "print(\"Precision:\", precision_score(yte_nl, y_pred_nl, zero_division=0),\n",
    "      \"Recall:\",   recall_score(yte_nl, y_pred_nl, zero_division=0),\n",
    "      \"F1:\",       f1_score(yte_nl, y_pred_nl, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de71b23",
   "metadata": {
    "tags": [
     "public"
    ]
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk4AAAGGCAYAAACNCg6xAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAB49ElEQVR4nO3dd1RUx9sH8O/CwtIX6aAIWFCJ0dhFY9BYELuxxoK9xBK70Rh7+9k1dg2IXWMvwUISjb1GExOMRgUbIILS++68fxj3daW4KHAp3885e447d+69zx1g93Fm7lyZEEKAiIiIiN5JT+oAiIiIiIoKJk5EREREOmLiRERERKQjJk5EREREOmLiRERERKQjJk5EREREOmLiRERERKQjJk5EREREOmLiRERERKQjJk5EhVRAQABkMhmuXbuW5fY2bdrA1dX1vY7duHFjNG7c+J31QkNDIZPJEBAQ8F7n0dW8efNw8OBBnevLZDKtl4WFBRo0aICdO3dmu8+lS5fQpUsXODo6wtDQEA4ODujcuTMuXryY7T5[…redacted-path…]",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# assumes you still have p_hat (linear statsmodels), p_hat_reg (impute+L2), and p_hat_nl (nonlinear+L2)\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "plt.figure(figsize=(6,4))\n",
    "\n",
    "def plot_roc(y, p, label):\n",
    "    fpr, tpr, _ = roc_curve(y, p)\n",
    "    auc = roc_auc_score(y, p)\n",
    "    plt.plot(fpr, tpr, label=f\"{label} (AUC={auc:.3f})\")\n",
    "\n",
    "plot_roc(y_test, p_hat,     \"SM Logit (linear)\")\n",
    "plot_roc(y_test, p_hat_reg, \"Sklearn L2 (linear)\")\n",
    "plot_roc(y_test, p_hat_nl,  \"Sklearn L2 + nonlinear\")\n",
    "plt.plot([0,1],[0,1],'--', lw=1)\n",
    "plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\"); plt.title(\"Holdout ROC (2017+)\")\n",
    "plt.legend(loc=\"lower right\"); plt.tight_layout(); plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9337bd2",
   "metadata": {
    "tags": [
     "public"
    ]
   },
   "outputs": [],
   "source": [
    "# Appendix: threshold diagnostics helper (final model)\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def evaluate_at_threshold(y_true, p, thr=0.5, title_suffix=\"(t=0.5)\"):\n",
    "    y_pred = (p >= thr).astype(int)\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=[0,1])  # rows=true, cols=pred\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "    rec  = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1   = f1_score(y_true, y_pred, zero_division=0)\n",
    "\n",
    "    print(f\"Threshold {title_suffix}\")\n",
    "    print(f\"TP={tp}  FP={fp}  FN={fn}  TN={tn}\")\n",
    "    print(f\"Precision={prec:.3f}  Recall={rec:.3f}  F1={f1:.3f}\")\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(4,3))\n",
    "    im = ax.imshow(cm, cmap=\"Blues\")\n",
    "    ax.set_title(f\"Confusion Matrix {title_suffix}\")\n",
    "    ax.set_xlabel(\"Predicted\"); ax.set_ylabel(\"Actual\")\n",
    "    ax.set_xticks([0,1]); ax.set_xticklabels([\"No Recession\",\"Recession\"])\n",
    "    ax.set_yticks([0,1]); ax.set_yticklabels([\"No Recession\",\"Recession\"])\n",
    "    cm_norm = cm / cm.sum(axis=1, keepdims=True)\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            ax.text(j, i, f\"{cm[i,j]}\\n({cm_norm[i,j]:.2f})\",\n",
    "                    ha=\"center\", va=\"center\", fontsize=9)\n",
    "    fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "    plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bf0104",
   "metadata": {
    "tags": [
     "public"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold (t=0.50)\n",
      "TP=0  FP=0  FN=2  TN=85\n",
      "Precision=0.000  Recall=0.000  F1=0.000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEiCAYAAADqL+XUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAABPw0lEQVR4nO3dd1gUx/8H8PfdAcdRjmakKKIISJGmqEGjaFSI3Ri7UYixJBoVjSXGKKgRlKgxllhQwdiN7aeJolgwBVQkogYRiCJohC8WBBSl3M3vD8KGo9wtBu8APy+ffR7ZmZ2d24P73MzszAoYYwyEEEKICkJNV4AQQkjDQAGDEEIILxQwCCGE8EIBgxBCCC8UMAghhPBCAYMQQggvFDAIIYTwQgGDEEIILxQwCCGE8EIBgwAArl+[…redacted-path…]",
      "text/plain": [
       "<Figure size 400x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Youden (final model) threshold: 0.047\n",
      "Threshold (t=0.047, Youden)\n",
      "TP=2  FP=28  FN=0  TN=57\n",
      "Precision=0.067  Recall=1.000  F1=0.125\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEiCAYAAADqL+XUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAABW4UlEQVR4nO3deVhUZfsH8O/MAMOwDJvKJqIIKCACbrgkaC7kvu8ZZC5vWmqm9poluARqZeaSCymYuZXb64ILqWiFmhtKioiKignhgqAg28z9+4MfJ0cGOBgMoPen61xXnuec5zxzZrl51iMhIgJjjDFWDml1F4AxxljtwAGDMcaYKBwwGGOMicIBgzHGmCgcMBhjjInCAYMxxpgoHDAYY4yJwgGDMcaYKBwwGGOMicIBQwcuXbqEd999F40aNYKhoSFMTEzQokULLF68GI8eParSa1+4cAH+[…redacted-path…]",
      "text/plain": [
       "<Figure size 400x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold (t=0.237, base-rate)\n",
      "TP=0  FP=8  FN=2  TN=77\n",
      "Precision=0.000  Recall=0.000  F1=0.000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAEiCAYAAAA8ij+xAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAABUu0lEQVR4nO3dd1gUV9sH4N/uAstSlqZUEaQoIIgoStQIGgt20WjskVhfNfaevAHUBMubmNgLKhh7YosaY4kKiRENFsSCgIotYrCgoEjd5/uDj4krC7u4CEKeO9dcV5xz5syZ2WGfPWfOnBEREYExxhjTgriqK8AYY6z642DCGGNMaxxMGGOMaY2DCWOMMa1xMGGMMaY1DiaMMca0xsGEMcaY1jiYMMYY0xoHE8YYY1rjYKKFhIQEfPLJJ6hXrx709fVhZGSEJk2aYNGiRXjy5Mlb3feFCxcQEBAAExMTiEQifPfddxW+D5FIhLCwsAovV52oqCiIRCKIRCJER0eXSCciuLi4QCQSoU2bNm+0j5UrVyIqKqpc20RHR5daJ23MnTsXHh4eUCgUAIDs7GyEhYVV+H7S09MRHByMWrVqwcDAAC1atMCxY8c02nbdunUICgqCo6MjZDIZXFxcMGbMGKSlpZXIO2LECHh6esLU1BQymQz169fH9OnT8ejRI6V8wcHBwuesajl9+nS5j7H4M9q5c2e5t63uKuK6SU5Ohp6eHs6fP1/+jYm9kbVr15KOjg41bNiQVqxYQSdOnKAjR45QeHg41atXj4KCgt7q/hs3bkyurq508OBBio2NpbS0tArfR2xsLN29e7fCy1UnMjKSAJCxsTENHjy4RPqJEyeE9ICAgDfaR8OGDcu97bNnzyg2NpaePXv2RvtU5a+[…redacted-path…]",
      "text/plain": [
       "<Figure size 400x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold (t=0.20, early-warning)\n",
      "TP=0  FP=8  FN=2  TN=77\n",
      "Precision=0.000  Recall=0.000  F1=0.000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ8AAAEiCAYAAAAmtt8/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAABWR0lEQVR4nO3dd1gUx/8H8PfdAXfHwdEMTRFEQUABsWGJoLFgF3tX7FFj7zECNizfxCR2RQVjN7bYBWs0YkMRCwIqiEYIKihIh5vfH/xu9eTgDoVD8fPy2eeRndnZ2b3yuZmdneUxxhgIIYQQDeJXdAUIIYR8fSj4EEII0TgKPoQQQjSOgg8hhBCNo+BDCCFE4yj4EEII0TgKPoQQQjSOgg8hhBCNo+BDCCFE4yj4vCcyMhLDhg1DjRo1IBKJoKenh/r162P58uVISUkp133funULnp6eMDAwAI/Hw2+[…redacted-path…]",
      "text/plain": [
       "<Figure size 400x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold (t=0.053, recall≥0.50)\n",
      "TP=1  FP=24  FN=1  TN=61\n",
      "Precision=0.040  Recall=0.500  F1=0.074\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZwAAAEiCAYAAADNgWQ8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAABZlUlEQVR4nO3dd1gUxxsH8O/dAcdRjqYcRUQRUFBEbIhGQVGJYo+9BKJRE0zsJZqfgiWgRE3ELioYo6KxRY29YRKwRoQIAURAjBBUVBCpd/P7g7DxqEc7FN6Pzz6P7OzOzu4evDezszM8xhgDIYQQUsf49V0AQgghjQMFHEIIIUpBAYcQQohSUMAhhBCiFBRwCCGEKAUFHEIIIUpBAYcQQohSUMAhhBCiFBRwCCGEKAUFnApERkbik08+QcuWLaGurg4tLS107NgR/v7+yMjIqNNj3717F87OztDR0QGPx8P3339f68fg8Xjw8fGp9XwrExwcDB6PBx6Ph6tXr5ZKZ4zB0tISPB4PLi4u1TrGli1bEBwcXKV9rl69Wm6ZamLFihWwtbWFTCYDALx58wY+Pj61fpz09HR4enqiSZMm0NDQgJOTEy5duqTw/g8fPsSIESOgq6sLLS0t9OvXD3/88Uep7Vq0aMHdv7eXzz77TG67iIgIuLu7o3nz5hCJRNDX14eTkxN+[…redacted-path…]",
      "text/plain": [
       "<Figure size 400x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Appendix: evaluate a few thresholds for the final model on 2017+ holdout\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Final-model probabilities on the holdout\n",
    "p_final_test = predict_probs_final(test_df)\n",
    "\n",
    "# 0.50 threshold\n",
    "evaluate_at_threshold(y_test, p_final_test, thr=0.50, title_suffix=\"(t=0.50)\")\n",
    "\n",
    "# Youden threshold\n",
    "fpr_, tpr_, thr_ = roc_curve(y_test, p_final_test)\n",
    "best_thr_final = thr_[(tpr_ - fpr_).argmax()]\n",
    "print(f\"Youden (final model) threshold: {best_thr_final:.3f}\")\n",
    "evaluate_at_threshold(y_test, p_final_test, thr=best_thr_final,\n",
    "                      title_suffix=f\"(t={best_thr_final:.3f}, Youden)\")\n",
    "\n",
    "# Base-rate threshold\n",
    "thr_base_final = float(np.quantile(p_final_test, 1 - y_train.mean()))\n",
    "evaluate_at_threshold(y_test, p_final_test, thr=thr_base_final,\n",
    "                      title_suffix=f\"(t={thr_base_final:.3f}, base-rate)\")\n",
    "\n",
    "# Early-warning 0.20\n",
    "evaluate_at_threshold(y_test, p_final_test, thr=0.20,\n",
    "                      title_suffix=\"(t=0.20, early-warning)\")\n",
    "\n",
    "# Target recall ≥ 0.50\n",
    "def threshold_for_recall(y_true, p, target_recall=0.60):\n",
    "    fpr, tpr, thr = roc_curve(y_true, p)\n",
    "    i = np.argmax(tpr >= target_recall)\n",
    "    return float(thr[i]) if i < len(thr) else 0.5\n",
    "\n",
    "thr_recall = threshold_for_recall(y_test, p_final_test, target_recall=0.50)\n",
    "evaluate_at_threshold(y_test, p_final_test, thr=thr_recall,\n",
    "                      title_suffix=f\"(t={thr_recall:.3f}, recall≥0.50)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34ba935",
   "metadata": {
    "tags": [
     "public"
    ]
   },
   "outputs": [],
   "source": [
    "# Appendix: Parameter-uncertainty MC (only for simple_logit winner)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "if best_name == \"simple_logit\":\n",
    "    beta_hat = res.params.values\n",
    "    cov_hat  = res.cov_params().values\n",
    "    design_cols = res.model.exog_names  # constant + feature order used in training\n",
    "\n",
    "    def predict_with_beta(X_mat, beta):\n",
    "        # X_mat is a NumPy array with columns in 'design_cols' order\n",
    "        z = X_mat @ beta\n",
    "        return 1.0 / (1.0 + np.exp(-z))\n",
    "\n",
    "    def mc_probs_with_param_uncertainty(path_df, sims=500, seed=42):\n",
    "        \"\"\"\n",
    "        path_df: DataFrame with base FEATURES (no constant). Rows = future dates (or any scenario path).\n",
    "        Returns: DataFrame with p10, p50, p90 indexed by path_df.index.\n",
    "        \"\"\"\n",
    "        # Build X with constant, then align to training design (fills missing with 0 if any)\n",
    "        X = sm.add_constant(path_df[FEATURES], has_constant=\"add\")\n",
    "        X = X.reindex(columns=design_cols, fill_value=0.0)\n",
    "        X_mat = X.to_numpy(dtype=float)\n",
    "\n",
    "        rng = np.random.default_rng(seed)\n",
    "        P = np.empty((sims, len(path_df)), dtype=float)\n",
    "\n",
    "        for s in range(sims):\n",
    "            beta_s = rng.multivariate_normal(beta_hat, cov_hat)\n",
    "            P[s, :] = predict_with_beta(X_mat, beta_s)\n",
    "\n",
    "        q10, q50, q90 = np.quantile(P, [0.10, 0.50, 0.90], axis=0)\n",
    "        return pd.DataFrame({\"p10\": q10, \"p50\": q50, \"p90\": q90}, index=path_df.index)\n",
    "else:\n",
    "    print(\"Parameter-uncertainty MC skipped: final model is not simple_logit.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373a200f",
   "metadata": {
    "tags": [
     "public"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved parameter-uncertainty bands → paper3_scenario_probs_param_mc.csv\n"
     ]
    }
   ],
   "source": [
    "#Appendix, after scenarios exists\n",
    "if best_name == \"simple_logit\":\n",
    "    seeds = {\"baseline\": 221, \"easing\": 222, \"stress\": 223}\n",
    "    mc_param = {name: mc_probs_with_param_uncertainty(df_s[FEATURES], sims=500, seed=seeds[name])\n",
    "                for name, df_s in scenarios.items()}\n",
    "\n",
    "    # Optional: save one combined CSV\n",
    "    out_param = (pd.concat(\n",
    "        [v.assign(scenario=k) for k, v in mc_param.items()]\n",
    "    ).reset_index().rename(columns={\"index\":\"Date\"}))\n",
    "    out_param.to_csv(\"paper3_scenario_probs_param_mc.csv\", index=False)\n",
    "    print(\"Saved parameter-uncertainty bands → paper3_scenario_probs_param_mc.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77917f8",
   "metadata": {
    "tags": [
     "public"
    ]
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABEEAAAHqCAYAAADrglBeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAADhAUlEQVR4nOzdd3gT9R8H8Heapm2696KLslr2hrIKFmQjCIoTRFFRFAFFBZElP1BARJHhQEFExYUDUIGCzJY9ZMtqge7dZo/7/VFzNCSlLbRNx/v1PH0gd9+7+9wld8l97jskgiAIICIiIiIiIiKq4+xsHQARERERERERUXVgEoSIiIiIiIiI6gUmQYiIiIiIiIioXmAShIiIiIiIiIjqBSZBiIiIiIiIiKheYBKEiIiIiIiIiOoFJkGIiIiIiIiIqF5gEoSIiIiIiIiI6gUmQYiIiIiIiIioXmAShIiq3cGDBzFixAiEhYXB0dERAQEBiImJwauvvmrr0CpN79690bt370pb31NPPQWJRCL+OTo6olmzZpg9ezbUanWlbefvv/+GRCLBjz/+WGnrXLt2LSQSCY4cOVJm2aeeegoRERFm0yIiIvDUU0+Jr69duwaJRIK1a9eK0w4cOIA5c+YgLy/PYp2V/V7YUu/evc0+B3K5HG3atMGyZctgNBptHV6V2rp1K+bMmVOt23zqqafg6upa6nxXV1ezz2ZNVBnHzdp5WV53OjfvNaaS54JUKkVISAgefvhhnD59ulK3VdG47vZYWXP58mU4OjoiISGhQsstWLAAv/zyy11vV6lUYs6cOfj777/veh22ZPreuXbtWoWXnTNnDiQSSYWWyc3Nhaen5z0dcyKqPkyCEFG12rJlC7p164aCggIsWrQI27Ztw4cffoju3btj48aNtg6v0qxcuRIrV66s1HXK5XIkJCQgISEBv/zyC7p06YJ58+Zh7NixlbodW3r77bexadOmO5YJCgpCQkICBg8eLE47cOAA5s6da/VGqyreC1uKjIwUPwcbN25EgwYNMGXKFEyfPt3WoVWprVu3Yu7cubYOo9apjONWnvOyNHc6N+9VyWvi7t27MX/+fBw7dgzdunXDzZs3K317tvDaa6+hX79+iImJqdBylZEEmTt3bq1NglQ3Ly8vTJkyBdOmTYNWq7V1OERUBntbB0BE9cuiRYvQsGFD/PXXX7C3v3UJeuSRR7Bo0SIbRlY5lEolnJ2d0bx580pft52dHbp27Sq+HjhwIK5du4bvv/8eS5cuRYMGDawup1KpIJfLKz2eqtCoUaMyyzg6Opodh7JUxXthS3K53OJzEBUVhY8[…redacted-path…]",
      "text/plain": [
       "<Figure size 1100x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved parameter-uncertainty bands → paper3_scenario_probs_param_mc.csv\n"
     ]
    }
   ],
   "source": [
    "# Appendix: Parameter-uncertainty bands (statsmodels) — only if simple_logit won\n",
    "if best_name == \"simple_logit\":\n",
    "    param_bands = {}\n",
    "    for name in [\"baseline\", \"easing\", \"stress\"]:\n",
    "        path = scenarios[name][FEATURES]  # only the 4 linear features\n",
    "        param_bands[name] = mc_probs_with_param_uncertainty(path, sims=1000, seed=123)\n",
    "\n",
    "    plt.figure(figsize=(11,5))\n",
    "    for name, q in param_bands.items():\n",
    "        plt.fill_between(q.index, q[\"p10\"], q[\"p90\"], alpha=0.2,\n",
    "                         label=f\"{name.capitalize()} (param 10–90%)\")\n",
    "        plt.plot(q.index, q[\"p50\"], lw=2)\n",
    "    plt.ylim(0, 1)\n",
    "    plt.ylabel(\"Recession Prob (12m ahead)\")\n",
    "    plt.title(\"Scenario Probabilities — Parameter Uncertainty Bands (statsmodels)\")\n",
    "    plt.legend(ncol=3, loc=\"upper center\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Optional: save a combined CSV\n",
    "    out_param = (pd.concat([v.assign(scenario=k) for k, v in param_bands.items()])\n",
    "                   .reset_index().rename(columns={\"index\": \"Date\"}))\n",
    "    out_param.to_csv(\"paper3_scenario_probs_param_mc.csv\", index=False)\n",
    "    print(\"Saved parameter-uncertainty bands → paper3_scenario_probs_param_mc.csv\")\n",
    "else:\n",
    "    print(\"Skipped parameter-uncertainty bands: final model is not simple_logit.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2319405",
   "metadata": {
    "tags": [
     "public"
    ]
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA90AAAGGCAYAAABmGOKbAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAACPqElEQVR4nOzdd3gUVdsG8Ht3s+mFFNI7vSMgEFpASEJAEERFUQEVFEUReOFV9FPAhqKIFURFEGxYkFelJUiXUKWHTgrpJIH0vuf7Y9lJNrub7EKSTbl/17VXdmfOzDxzMoR59pw5RyaEECAiIiIiIiKiOic3dwBEREREREREzRWTbiIiIiIiIqJ6wqSbiIiIiIiIqJ4w6SYiIiIiIiKqJ0y6iYiIiIiIiOoJk24iIiIiIiKiesKkm4iIiIiIiKieMOkmIiIiIiIiqidMuomIiIiIiIjqCZNuohbo0KFDGD9+PPz9/WFlZQUPDw+EhITgP[…redacted-path…]",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Appendix: Scenario probability plot (from canonical CSV)\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#scen_wide = pd.read_csv(\"paper3_scenario_probs.csv\", parse_dates=[\"Date\"]).set_index(\"Date\")\n",
    "# [redacted] Critical operation disabled in public copy (data access or training).\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "for name in [\"baseline\", \"easing\", \"stress\"]:\n",
    "    if name in scen_wide.columns:\n",
    "        plt.plot(scen_wide.index, scen_wide[name], label=name.capitalize())\n",
    "plt.ylim(0, 1)\n",
    "plt.xlabel(\"Date\"); plt.ylabel(\"Recession Prob (12m ahead)\")\n",
    "plt.title(\"Scenario-based Conditional Recession Probabilities (Final Model)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2156e91",
   "metadata": {
    "tags": [
     "public"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Youden thr (L2)=0.083 | TP=2 FP=28 FN=0 TN=57\n",
      "Precision: 0.06666666666666667 Recall: 1.0 F1: 0.125\n"
     ]
    }
   ],
   "source": [
    "# Appendix (Optional) confusion matrix at Youden or custom threshold\n",
    "from sklearn.metrics import roc_curve, confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n",
    "fpr, tpr, thr = roc_curve(yte, p_hat_reg)\n",
    "best_thr_l2 = thr[(tpr - fpr).argmax()]\n",
    "y_pred = (p_hat_reg >= best_thr_l2).astype(int)\n",
    "\n",
    "cm = confusion_matrix(yte, y_pred, labels=[0,1])\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "print(f\"Youden thr (L2)={best_thr_l2:.3f} | TP={tp} FP={fp} FN={fn} TN={tn}\")\n",
    "print(\"Precision:\", precision_score(yte, y_pred, zero_division=0),\n",
    "      \"Recall:\", recall_score(yte, y_pred, zero_division=0),\n",
    "      \"F1:\", f1_score(yte, y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50e9a9e",
   "metadata": {
    "tags": [
     "public"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance comparison (Paper 3):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "<[…redacted-path…]\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th><[…redacted-path…]\n",
       "      <th>Model<[…redacted-path…]\n",
       "      <th>AUC (test)<[…redacted-path…]\n",
       "      <th>McFadden R²<[…redacted-path…]\n",
       "      <th>ΔAUC vs YieldCurveOnly<[…redacted-path…]\n",
       "      <th>ΔR² vs YieldCurveOnly<[…redacted-path…]\n",
       "    <[…redacted-path…]\n",
       "  <[…redacted-path…]\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0<[…redacted-path…]\n",
       "      <td>YieldCurveOnly<[…redacted-path…]\n",
       "      <td>0.712<[…redacted-path…]\n",
       "      <td>0.213<[…redacted-path…]\n",
       "      <td>0.000<[…redacted-path…]\n",
       "      <td>0.000<[…redacted-path…]\n",
       "    <[…redacted-path…]\n",
       "    <tr>\n",
       "      <th>1<[…redacted-path…]\n",
       "      <td>MacroAugmented<[…redacted-path…]\n",
       "      <td>0.694<[…redacted-path…]\n",
       "      <td>0.251<[…redacted-path…]\n",
       "      <td>-0.018<[…redacted-path…]\n",
       "      <td>0.038<[…redacted-path…]\n",
       "    <[…redacted-path…]\n",
       "  <[…redacted-path…]\n",
       "<[…redacted-path…]\n",
       "<[…redacted-path…]"
      ],
      "text/plain": [
       "            Model  AUC (test)  McFadden R²  ΔAUC vs YieldCurveOnly  \\\n",
       "0  YieldCurveOnly       0.712        0.213                   0.000   \n",
       "1  MacroAugmented       0.694        0.251                  -0.018   \n",
       "\n",
       "   ΔR² vs YieldCurveOnly  \n",
       "0                  0.000  \n",
       "1                  0.038  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === Post-hoc performance summary (robust) ===\n",
    "# Compares Yield-Curve-Only vs Macro-Augmented on TEST set\n",
    "# Assumes:\n",
    "#   - Split frames exist: train_df, test_df\n",
    "#   - TARGET column is 'recession_t12'\n",
    "#   - FEATURES (macro-augmented) includes 'YC_10y_3m' + 3 macro vars used in your Paper 3\n",
    "import numpy as np, pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# --- config (edit only if your names differ) ---\n",
    "TARGET = \"recession_t12\"\n",
    "YIELD_ONLY = [\"YC_10y_3m\"]          # <- your YC feature name\n",
    "\n",
    "# --- guards ---\n",
    "for nm in [\"train_df\",\"test_df\"]:\n",
    "    if nm not in globals():\n",
    "        raise RuntimeError(f\"{nm} not found. Re-run the split cell that creates train/test frames.\")\n",
    "if \"FEATURES\" not in globals():\n",
    "    raise RuntimeError(\"FEATURES not found. Re-run the cell that sets your 4 predictors.\")\n",
    "\n",
    "missing_train = sorted(set([TARGET] + YIELD_ONLY + FEATURES) - set(train_df.columns))\n",
    "missing_test  = sorted(set([TARGET] + YIELD_ONLY + FEATURES) - set(test_df.columns))\n",
    "if missing_train or missing_test:\n",
    "    raise RuntimeError(f\"Missing column[…redacted-path…]\n",
    "\n",
    "def _fit_logit(df, cols):\n",
    "    X = sm.add_constant(df[cols], has_constant=\"add\").copy()\n",
    "    y = df[TARGET].astype(int)\n",
    "    # align/drop NA rows consistently\n",
    "    X = X.replace([np.inf,-np.inf], np.nan).dropna(axis=0, how=\"any\")\n",
    "    y = y.loc[X.index]\n",
    "    model = sm.Logit(y, X)\n",
    "#    res = model.fit(disp=False)\n",
    "# [redacted] Critical operation disabled in public copy (data access or training).\n",
    "    return res, X.columns  # keep training design\n",
    "\n",
    "def _predict_probs(res, df, train_cols):\n",
    "    X = sm.add_constant(df[train_cols.difference([\"const\",\"_cons\"], sort=False)], has_constant=\"add\")\n",
    "    # Reindex to exact train design, fill missing with 0 (none if same columns)\n",
    "    X = X.reindex(columns=train_cols, fill_value=0.0)\n",
    "    X = X.replace([np.inf,-np.inf], np.nan).dropna(axis=0, how=\"any\")\n",
    "    p = res.predict(X)\n",
    "    return np.asarray(p), X.index\n",
    "\n",
    "def _safe_auc(y_true, y_prob):\n",
    "    try:\n",
    "        return roc_auc_score(y_true, y_prob)\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "# --- Macro-augmented model ---\n",
    "# Use in-memory 'res' if it exists; otherwise refit with FEATURES on train_df\n",
    "if \"res\" in globals():\n",
    "    res_macro = res\n",
    "    # infer training column order\n",
    "    macro_cols = pd.Index(getattr(res_macro, \"params\", pd.Series(index=[])).index)\n",
    "    if macro_cols.empty:\n",
    "        macro_cols = pd.Index(getattr(getattr(res_macro, \"model\", None), \"exog_names\", []))\n",
    "else:\n",
    "    res_macro, macro_cols = _fit_logit(train_df, FEATURES)\n",
    "\n",
    "# --- Yield-curve-only baseline (refit quickly) ---\n",
    "res_yc, yc_cols = _fit_logit(train_df, YIELD_ONLY)\n",
    "\n",
    "# --- Evaluate on TEST set ---\n",
    "y_test = test_df[TARGET].astype(int)\n",
    "\n",
    "p_macro, idx_macro = _predict_probs(res_macro, test_df, macro_cols)\n",
    "auc_macro = _safe_auc(y_test.loc[idx_macro], p_macro)\n",
    "\n",
    "p_yc, idx_yc = _predict_probs(res_yc, test_df, yc_cols)\n",
    "auc_yc = _safe_auc(y_test.loc[idx_yc], p_yc)\n",
    "\n",
    "# --- McFadden pseudo-R^2 (training-set based; standard definition) ---\n",
    "def mcfadden_r2(res_obj):\n",
    "    try:\n",
    "        return 1.0 - (res_obj.llf / res_obj.llnull)\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "r2_macro = mcfadden_r2(res_macro)\n",
    "r2_yc    = mcfadden_r2(res_yc)\n",
    "\n",
    "# --- assemble tidy summary ---\n",
    "perf_summary = pd.DataFrame(\n",
    "    [\n",
    "        [\"YieldCurveOnly\",  auc_yc,    r2_yc],\n",
    "        [\"MacroAugmented\",  auc_macro, r2_macro],\n",
    "    ],\n",
    "    columns=[\"Model\",\"AUC (test)\",\"McFadden R²\"]\n",
    ")\n",
    "base_auc = perf_summary.loc[perf_summary[\"Model\"]==\"YieldCurveOnly\",\"AUC (test)\"].values[0]\n",
    "base_r2  = perf_summary.loc[perf_summary[\"Model\"]==\"YieldCurveOnly\",\"McFadden R²\"].values[0]\n",
    "perf_summary[\"ΔAUC vs YieldCurveOnly\"] = perf_summary[\"AUC (test)\"] - base_auc\n",
    "perf_summary[\"ΔR² vs YieldCurveOnly\"]  = perf_summary[\"McFadden R²\"] - base_r2\n",
    "\n",
    "print(\"Performance comparison (Paper 3):\")\n",
    "display(perf_summary.round(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523b8870",
   "metadata": {
    "tags": [
     "public"
    ]
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
